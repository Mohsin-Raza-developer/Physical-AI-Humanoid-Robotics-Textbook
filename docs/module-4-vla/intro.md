---
title: Vision-Language-Action Models
sidebar_label: VLA Overview
sidebar_position: 1
description: Understanding Vision-Language-Action models in robotics
---

# Vision-Language-Action Models

This section covers Vision-Language-Action (VLA) models for robotics applications in Physical AI.

## Learning Objectives

After completing this module, you will be able to:
- Understand VLA model architectures
- Implement VLA models for robotic tasks
- Connect perception to action
- Integrate language understanding with robotics

## Table of Contents

- [VLA Model Architectures](./vla-architectures)
- [Training VLA Models](./training-vla)
- [VLA for Robotic Control](./vla-control)
- [VLA in Physical AI Systems](./vla-physical-ai)