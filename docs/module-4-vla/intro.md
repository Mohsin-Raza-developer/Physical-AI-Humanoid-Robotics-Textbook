---
title: Vision-Language-Action Models
sidebar_label: VLA Overview
sidebar_position: 1
description: Understanding Vision-Language-Action models in robotics
---

# Vision-Language-Action Models

This section covers Vision-Language-Action (VLA) models for robotics applications in Physical AI.

## Learning Objectives

After completing this module, you will be able to:
- Understand VLA model architectures
- Implement VLA models for robotic tasks
- Connect perception to action
- Integrate language understanding with robotics

## Table of Contents

- [Humanoid Kinematics](./week-11-lesson-1-humanoid-kinematics)
- [Manipulation & Grasping](./week-12-lesson-1-manipulation-grasping)
- [Conversational Robotics](./week-13-lesson-1-conversational-robotics)
- [Capstone Project](./week-13-lesson-3-capstone-project)